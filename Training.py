# -------------------------------------------
# Incremental training for animal folders (Colab + Drive)
# -------------------------------------------

import os, shutil, errno, time
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, Dataset
from PIL import Image

# ----------------- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ -----------------
drive_dir = "/content/drive/MyDrive"
data_dir = f"{drive_dir}/animals"       # <-- Ø¹Ø¯Ù‘Ù„ Ù„Ùˆ Ø§Ø³Ù… Ø§Ù„ÙÙˆÙ„Ø¯Ø± Ù…Ø®ØªÙ„Ù
model_path = f"{drive_dir}/animal_model.pth"
trained_folders_file = f"{drive_dir}/trained_folders.txt"

temp_dir = "/content/temp_animals"      # Ù…Ø¬Ù„Ø¯ Ù…Ø¤Ù‚Øª ÙÙŠ Ø¨ÙŠØ¦Ø© Colab
batch_size = 32
num_epochs = 5
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„ØµÙˆØ±
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])
])

# ----------------- Ø¬Ù„Ø¨ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙÙˆÙ„Ø¯Ø±Ø§Øª -----------------
if not os.path.exists(data_dir):
    raise FileNotFoundError(f"Data dir not found: {data_dir}\nØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ù…Ø³Ø§Ø± ØµØ­ÙŠØ­ Ø¯Ø§Ø®Ù„ Drive")

all_folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))])
print("Found folders in Drive:", len(all_folders))

# Ø§Ù‚Ø±Ø£ Ø§Ù„ÙÙˆÙ„Ø¯Ø±Ø§Øª Ø§Ù„Ù…ØªØ¯Ø±Ø¨Ø© Ø³Ø§Ø¨Ù‚Ù‹Ø§ Ø¥Ù† ÙˆØ¬Ø¯Øª
if os.path.exists(trained_folders_file):
    with open(trained_folders_file, "r") as f:
        trained_folders = [x for x in f.read().splitlines() if x.strip()]
else:
    trained_folders = []

remaining_folders = [f for f in all_folders if f not in trained_folders]
next_folders = remaining_folders[:10]   # Ù†Ø§Ø®Ø¯ 10 ÙƒÙ„ Ù…Ø±Ø©

if not next_folders:
    print("âœ… ÙƒÙ„ Ø§Ù„ÙÙˆÙ„Ø¯Ø±Ø§Øª ØªÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„ÙŠÙ‡Ø§ Ø¨Ø§Ù„ÙØ¹Ù„.")
else:
    print(f"ğŸ“‚ Ø³ÙŠØªÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„ÙÙˆÙ„Ø¯Ø±Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©: {next_folders}")

    # -------------------------------------
    # Ù†Ø³Ø® Ø¢Ù…Ù† Ù…Ù† Drive -> temp_dir (ØªØ¬Ø§ÙˆØ² Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙƒØ³ÙˆØ±Ø©)
    # -------------------------------------
    if os.path.exists(temp_dir):
        shutil.rmtree(temp_dir)
    os.makedirs(temp_dir, exist_ok=True)

    for folder in next_folders:
        src_folder = os.path.join(data_dir, folder)
        dst_folder = os.path.join(temp_dir, folder)
        os.makedirs(dst_folder, exist_ok=True)

        for root, _, files in os.walk(src_folder):
            rel_path = os.path.relpath(root, src_folder)
            dst_path = os.path.join(dst_folder, rel_path) if rel_path != "." else dst_folder
            os.makedirs(dst_path, exist_ok=True)

            for file in files:
                src_file = os.path.join(root, file)
                dst_file = os.path.join(dst_path, file)
                try:
                    # Ù†Ø³Ø®Ø© Ø¢Ù…Ù†Ø©: copy2 Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ metadata
                    shutil.copy2(src_file, dst_file)
                except (OSError, IOError) as e:
                    # ØªØ¬Ø§Ù‡Ù„ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø£Ùˆ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø£Ùˆ Ù…Ù„ÙØ§Øª ØªØ§Ù„ÙØ©
                    err_no = getattr(e, "errno", None)
                    print(f"âš ï¸ ØªØ®Ø·ÙŠ Ù…Ù„Ù ØªØ§Ù„Ù Ø£Ùˆ ØºÙŠØ± Ù…ØªØ§Ø­: {src_file}  ({e})")
                    continue

    # -------------------------------------
    # Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© + Ø§Ù„Ø¬Ø¯Ø§Ø¯)
    # -------------------------------------
    all_trained = trained_folders + next_folders
    print("Total classes after this run:", len(all_trained))

    # -------------------------------------
    # Ù†Ø­Ù…Ù„ Ø§Ù„Ø¯Ø§ØªØ§ Ù…Ù† temp_dir (Ø§Ù„Ù„ÙŠ ÙÙŠÙ‡ ÙÙ‚Ø· Ø§Ù„Ù€ next_folders)
    # Ø«Ù… Ù†ÙØ¹ÙŠØ¯ ØªØ±Ù…ÙŠØ² Ø§Ù„Ù€ labels Ù„ØªØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ù€ all_trained indices
    # -------------------------------------
    temp_dataset = datasets.ImageFolder(temp_dir, transform=transform)
    # temp_dataset.classes == Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙÙˆÙ„Ø¯Ø±Ø§Øª ÙÙŠ temp_dir (Ù…Ø±ØªØ¨Ø© Ø£Ø¨Ø¬Ø¯ÙŠÙ‹Ø§)
    # Ù†Ø®Ù„Ù‚ mapping Ù…Ù† Ø§Ø³Ù… Ø§Ù„ÙƒÙ„Ø§Ø³ -> global_index
    global_class_to_idx = {name: idx for idx, name in enumerate(all_trained)}

    # Wrapper dataset Ù„ÙŠØ¹ÙŠØ¯ ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ù„Ù„Ù€ global indices
    class RemappedDataset(Dataset):
        def __init__(self, imagefolder_dataset, global_map):
            self.samples = imagefolder_dataset.samples   # list of (path, local_label)
            self.transform = imagefolder_dataset.transform
            self.local_classes = imagefolder_dataset.classes
            self.global_map = global_map

        def __len__(self):
            return len(self.samples)

        def __getitem__(self, idx):
            path, local_label = self.samples[idx]
            img = Image.open(path).convert("RGB")
            if self.transform:
                img = self.transform(img)
            local_class_name = self.local_classes[local_label]
            global_label = self.global_map[local_class_name]
            return img, global_label

    train_dataset = RemappedDataset(temp_dataset, global_class_to_idx)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)

    # -------------------------------------
    # Ù†Ù…ÙˆØ°Ø¬ ResNet18 Ù…Ø¹ ØªÙˆØ³ÙŠØ¹ Ø·Ø¨Ù‚Ø© Ø§Ù„Ù€ fc Ù„ØªÙ†Ø§Ø³Ø¨ Ø¹Ø¯Ø¯ all_trained
    # -------------------------------------
    model = models.resnet18(pretrained=True)
    num_features = model.fc.in_features
    new_num_classes = len(all_trained)
    model.fc = nn.Linear(num_features, new_num_classes)
    model = model.to(device)

    # -------------------------------------
    # Ù„Ùˆ ÙÙŠ Ù…ÙˆØ¯ÙŠÙ„ Ù‚Ø¯ÙŠÙ…: Ù†Ø­Ø§ÙˆÙ„ Ù†Ø­Ù…Ù„Ù‡ ÙˆÙ†Ù†Ù‚Ù„ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù€ fc Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
    # -------------------------------------
    if os.path.exists(model_path):
        print("ğŸ“¦ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙˆØ¯ÙŠÙ„ Ø³Ø§Ø¨Ù‚. Ø¬Ø§Ø±Ù Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©...")
        old_state = torch.load(model_path, map_location=device)
        # Ù†Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù€ fc Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø¥Ù† ÙˆØ¬Ø¯Øª
        old_fc_w = old_state.get('fc.weight', None)
        old_fc_b = old_state.get('fc.bias', None)

        # Ù†Ø­Ù…Ù„ Ø¨Ø§Ù‚ÙŠ Ø§Ù„state_dict (strict=False Ø¹Ù„Ø´Ø§Ù† Ø­Ø¬Ù… fc ÙŠÙ…ÙƒÙ† ÙŠØ®ØªÙ„Ù)
        try:
            model.load_state_dict(old_state, strict=False)
            print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø¸Ù… Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø¨Ù†Ø¬Ø§Ø­ (Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø·Ø¨Ù‚Ø© fc Ø¥Ù† ÙˆÙØ¬Ø¯Øª).")
        except Exception as e:
            print("âš ï¸ Ø­ØµÙ„ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„state dict Ø¨Ø´ÙƒÙ„ ØºÙŠØ± ØµØ§Ø±Ù…:", e)

        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø£ÙˆØ²Ø§Ù† Ù‚Ø¯ÙŠÙ…Ø© Ù„Ù„Ù€ fcØŒ Ù†Ù†Ù‚Ù„Ù‡Ø§ Ù„Ù„ØµÙÙˆÙ Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù…Ù† fc Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        if old_fc_w is not None and old_fc_b is not None:
            try:
                old_num = old_fc_w.shape[0]
                copy_num = min(old_num, new_num_classes)
                with torch.no_grad():
                    model.fc.weight.data[:copy_num].copy_(old_fc_w[:copy_num])
                    model.fc.bias.data[:copy_num].copy_(old_fc_b[:copy_num])
                print(f"ğŸ” ØªÙ… Ù†Ù‚Ù„ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù€ fc Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ù„Ù„Ø£ÙˆÙ„ {copy_num} ÙƒÙ„Ø§Ø³Ø§Øª.")
            except Exception as e:
                print("âš ï¸ ÙØ´Ù„ Ù†Ù‚Ù„ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù€ fc Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©:", e)

    # -------------------------------------
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    # -------------------------------------
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # -------------------------------------
    # ØªØ¯Ø±ÙŠØ¨
    # -------------------------------------
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        total_batches = 0
        for images, labels in train_loader:
            images = images.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            total_batches += 1

        avg_loss = running_loss / max(1, total_batches)
        print(f"Epoch [{epoch+1}/{num_epochs}]  Loss: {avg_loss:.4f}")

    # -------------------------------------
    # Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ù€ trained_folders_file
    # -------------------------------------
    torch.save(model.state_dict(), model_path)
    print("ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙÙŠ:", model_path)

    # Ù†Ø­Ø¯Ù‘Ø« trained_folders_file (Ù†ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡ ØªØ±ØªÙŠØ¨ Ø«Ø§Ø¨Øª)
    updated_trained = trained_folders + next_folders
    with open(trained_folders_file, "w") as f:
        f.write("\n".join(updated_trained))
    print("âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ù…Ù„Ù trained_folders.txt")

    # ØªÙ†Ø¸ÙŠÙ temp_dir Ù„Ùˆ Ø­Ø¨ÙŠØª (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
    # shutil.rmtree(temp_dir)
    print("ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©.")
